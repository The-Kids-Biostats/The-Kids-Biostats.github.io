---
title: "Analysing Pre-Post data"
format:
  html:
    code-fold: true
    toc: true
    toc-location: left
date: "2024-06-07"
author: "Dr Matthew Cooper"
categories:
  - Missing Data
  - Mixed Models
  - R
draft: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F, warning = F)

library(lme4); library(merTools); library(AER)
library(gtsummary); library(jtools); library(parameters)
library(patchwork); library(tidyverse); library(data.table)

theme_clean <- function() {
  theme_minimal(base_family = "Barlow Semi Condensed") +
    theme(panel.grid.minor = element_blank(),
          plot.title = element_text(family = "BarlowSemiCondensed-Bold"),
          axis.title = element_text(family = "BarlowSemiCondensed-Medium"),
          strip.text = element_text(family = "BarlowSemiCondensed-Bold",
                                    size = rel(1), hjust = 0),
          strip.background = element_rect(fill = "grey80", color = NA))
}
```

# Overview

Pre-post designs are in use everywhere we look. Before and after treatment, e.g. in a randomised clinical trial, might be the example most readily comes to mind for analysts in the health sciences area. However, the pre-post concept occurs in many non-randomised settings as well, like observational studies or retrospective policy evaluation studies, and can feature in our daily lives without use even knowing it (like in A/B testing to see if you spend just a little bit longer on social media).

While in principle, the set-up (premise) for such a question seems straight forward, there is extensive literature debating the different approaches to the analysis of data structured this way. The discussions around these choices may confuse the lay or even semi-experienced analyst reader. Often these discussions are held without a serviceable example to illustrate implementation.

So, here we go.

# Analysis options

When we have pre-post data (focusing on continuous, approximately normally distributed data here), there three approaches analysts may reach for:

-   **change score analysis**
    -   the outcome variable for each case is reduced one data point ('post value' - 'pre value')
    -   can be analysed as the outcome variable of a linear regression model with the treatment variable as the exposure of interest (on the right hand side (RHS) of the model)
    -   can just be analysed via a T-test
-   **linear regression**
    -   the data is structured as one row per case, with two variables representation the outcome (one for pre, one for post)
    -   the outcome variable is the post measurement with the treatment variable as the exposure of interest (RHS of the model)
    -   i\) ANCOVA framework, with the outcome variable is the post measurement, the treatment variable as the exposure of interest, and the pre measurement as an adjustment variable **\[typically, this is the recommended way to analyse pre-post data\]\***
-   **linear mixed effects models**
    -   can be structured in the same way as linear regression, via an ANCOVA framework (and this will reduce to linear regression in certain situations, OR
    -   ii\) the data is structured as two rows per case, with one variable representing the outcome, with one row for the pre measurement and one row for the post measurement (here, in a sense, pre-post represents a time variable)
        -   then, both the pre and post measurements are on the left hand side (LHS) of the model, with the treatment variable as the exposure of interest and the 'time variable' on the RHS of the model)

*\*typically, statisticians are very reserved about making broad sweeping methodological recommendations, typically - I share that reservation, but pragmatically speaking, ANCOVA is typically the go to for a lot of analysts in a lot of pre-post scenarios.*

We are really going to focus on i and ii as labelled above.

# Setting the scene

We're going to use some simulated data here, generated using the [`simstudy`](https://cran.r-project.org/web/packages/simstudy/index.html) package.

We generate a dataset based on the following:

-   data for 204 treatment patients
    -   Pre data has a mean of 20, post data has a mean of 50
    -   Both have an SD of 7.5
-   data for 197 control patients
    -   Pre data has a mean of 10, post data has a mean of 20
    -   Both have an SD of 5
-   pre data is measured between days (time) 0 to 28 \[largely ignored\]
-   post data is measured between days (time) 150 and 210 \[largely ignored\]
-   there is no inforced relationship between an individuals pre and post measurements (in general they all go up, but it's noisy)

For full readability, we do this in four steps, and then combine. Let's have a look.

```{r}
# Initialize random seed for reproducibility
set.seed(2024)

# Generate Treatment group data
dtTreatPre <- data.table(id = 1:204, group = "Treatment", time = sample(0:28, 204, replace = TRUE), 
                         Out = rnorm(204, mean = 20, sd = 7.5), timepoint = "Pre")
dtTreatPost <- data.table(id = 1:204, group = "Treatment", time = sample(150:210, 204, replace = TRUE), 
                          Out = dtTreatPre$Out + rnorm(204, mean = 50, sd = 7.5), timepoint = "Post")

# Generate Control group data
dtControlPre <- data.table(id = 205:401, group = "Control", time = sample(0:28, 197, replace = TRUE), 
                           Out = pmax(rnorm(197, mean = 10, sd = 5), 0), timepoint = "Pre")
dtControlPost <- data.table(id = 205:401, group = "Control", time = sample(150:210, 197, replace = TRUE), 
                            Out = dtControlPre$Out + rnorm(197, mean = 20, sd = 5), timepoint = "Post")

# Combine data
dtCombined <- rbind(dtTreatPre, dtTreatPost, dtControlPre, dtControlPost)
```

```{r}
dtCombined
```

```{r}
dtCombined %>% 
  mutate(timepoint = factor(timepoint, levels = c("Pre", "Post"))) %>% 
  group_by(group, timepoint) %>% 
  summarise(`Group Means` = mean(Out),
            `Group SDs` = sd(Out))
```

### Some visuals of our data

```{r echo=T, fig.align='center', fig.width=10, fig.height=5}
#dat %>% 
#  ggplot(aes(t, lwage, colour = gender)) +
#  geom_point(alpha = 0.15) +
#  geom_line(aes(group = id), alpha = 0.15) + 
#  facet_wrap(~ gender) +
#  scale_colour_viridis_d(option = "viridis", end = 0.4) +
#  theme_clean() +
#  theme(legend.position="none") +
#  labs(x = "Time (years)", y = "Wage (logged)") +
#  coord_cartesian(xlim = c(0,7),
#                  ylim = c(4.5,9))
```

## Research question

Are there differences in the rate of wage growth between males and females over time (in this dataset)?

That question is quite straightforward to answer here, but the motivating commentary is really around how mixed effects model can be beneficial in the presence of systematic missing (follow-up) data - with a focus on parameter estimates and their graphical interpretation.

Missing follow-up data (lost to follow, attrition, drop out) is often seen in health research datasets. The data might be Missing At Random, it my be Missing Completely At Random, the important nuances of these are largely out of scope for this post.

# Data inspection

Let's take an initial look at the data.

```{r echo = T}
data("PSID7682")
dat <- PSID7682 %>% 
  mutate(gender = case_when(gender == "male" ~ "Male",
                            T ~ "Female"),
         gender = factor(gender),
         gender = relevel(gender, "Male"),
         lwage = log(wage)) %>% 
  group_by(id) %>% 
  mutate(t = 1:7)
head(dat)
```

How much data do we have?

```{r echo = T}
dat %>% 
  ungroup() %>% 
  select(gender, t) %>% 
  tbl_summary(by = gender,
              statistic = all_categorical() ~ "{n}")
```

Data for 595 individuals across 7 time points - as expected.

And, what does the wage data look like?

```{r echo=T, fig.align='center', fig.width=10, fig.height=5}
dat %>% 
  ggplot(aes(t, wage, colour = gender)) +
  geom_point(alpha = 0.15) +
  geom_line(aes(group = id), alpha = 0.15) + 
  facet_wrap(~ gender) +
  scale_colour_viridis_d(option = "viridis", end = 0.4) +
  theme_clean() +
  theme(legend.position="none") +
  labs(x = "Time (years)", y = "Wage")
```

We can see that, generally the wage goes up at a fairly steady rate for most individuals across the 7 years of follow-up. We can also see some characteristics (upper skew, heteroskedasticity) that are likely to invalidate some modeling assumptions.

Let's look at the log of wage.

```{r echo=T, fig.align='center', fig.width=10, fig.height=5}
dat %>% 
  ggplot(aes(t, lwage, colour = gender)) +
  geom_point(alpha = 0.15) +
  geom_line(aes(group = id), alpha = 0.15) + 
  facet_wrap(~ gender) +
  scale_colour_viridis_d(option = "viridis", end = 0.4) +
  theme_clean() +
  theme(legend.position="none") +
  labs(x = "Time (years)", y = "Wage (logged)") +
  coord_cartesian(xlim = c(0,7),
                  ylim = c(4.5,9))
```

This now looks more homoskedastic (variability looks more consistent over time).

# Modelling the complete data

## Erroneous basic linear regression model

To address the question of **"are there differences between genders in the rate of wage growth"**, we are going to fit a gender by time interaction term which will give us an indication of if 'as time changes' whether the outcome (logged wage) changes at a different rate for each gender.

```{r echo = T}
mod1 <- lm(lwage ~ gender * t, data = dat)
export_summs(mod1, error_format = "[{conf.low}, {conf.high}]",
             error_pos = "right", digits = 3,
             statistics = c(N = "nobs"))
```

We can see there is an effect of gender present, and an effect of time (the growth overtime we saw in the original plot), but the very small beta coefficient (relative to the scale of data we are working with) and the p-value of 0.6 are suggestive that the rate of wage growth over time does not differ significantly between genders.

To view this, we're not going to use `geom_smooth` or `stat_summary` as we might do when graphing on-the-fly, rather we will use the predict() function to create data for our line of best fit.

To set a coding framework which we'll use again later in the post, we'll create a new dataset and use predictions to draw our (straight) line.

```{r echo = T}
newdat <- expand.grid(t = 1:7, gender = c("Male", "Female")) %>% 
  mutate(gender = factor(gender),
         gender = relevel(gender, "Male"))

p_mod1 <- cbind(newdat, 
                lwage = predict(mod1, newdat, interval = "prediction"))
```

```{r echo=T, fig.align='center', fig.width=10, fig.height=5}
dat %>% 
  ggplot(aes(t, lwage, colour = gender)) +
  geom_point(alpha = 0.15) +
  geom_line(aes(group = id), alpha = 0.15) + 
  facet_wrap(~ gender) +
  geom_line(data = p_mod1, aes(y = lwage.fit), colour = "red", linewidth = 1) +
  scale_colour_viridis_d(option = "viridis", end = 0.4) +
  theme_clean() +
  theme(legend.position="none") +
  labs(x = "Time (years)", y = "Wage (logged)") +
  coord_cartesian(xlim = c(0,7),
                  ylim = c(4.5,9))
```

Okay, these red fitted lines look like quite good as a 'line of best fit'; they pass the eye test of broadly representing the trends of the data well.

Fitted with a prediction confidence interval, we see.

```{r echo=T, fig.align='center', fig.width=10, fig.height=5}
p_mod1 %>% 
  ggplot(aes(t, lwage.fit, ymin = lwage.lwr, ymax = lwage.upr, fill = gender)) +
  geom_ribbon(alpha = 0.5) +
  geom_line(colour = "black", linewidth = 1) + 
  facet_wrap(~ gender) +
  scale_fill_viridis_d(option = "viridis", end = 0.4) +
  theme_clean() +
  theme(legend.position="none") +
  labs(x = "Time (years)", y = "Wage (logged)")  +
  coord_cartesian(xlim = c(0,7),
                  ylim = c(4.5,9)) -> p1
p1
```

These lines look parallel - suggestive of no difference in growth rates between the genders (in line with the non-significant interaction term we saw).

[Of course, we have not adjusted for the within person correlation present in the data.]{.underline} The model above is inappropriate as one of the main assumptions of the model is violated - the data points are not all independent (we know there are 7 from each individual).

## Mixed effects model

Here we run a fairly basic linear mixed effects model, the model has the same fixed effects terms as above (the interaction term we are curious about) but also includes a random effect, that is, the intercept is allowed to varied for each individual.

```{r echo = T}
mod2 <- lmer(lwage ~ gender * t + (1 | id), data = dat)
export_summs(mod2, error_format = "[{conf.low}, {conf.high}]",
             error_pos = "right", digits = 3,
             statistics = c(N = "nobs"))
```

Lets also fit the predicted values from this model.

```{r echo = T}
newdat <- expand.grid(t = 1:7, gender = c("Male", "Female")) %>% 
  mutate(gender = factor(gender),
         gender = relevel(gender, "Male"),
         id = c(rep(1, 7), rep(2, 7)))

store <- simulate(mod2, seed=1, newdata=newdat, re.form=NA,
                  allow.new.levels=T, nsim = 500)

p_mod2 <- cbind(newdat,
                store %>% 
                  rowwise() %>% 
                  mutate(fit = mean(c_across(sim_1:sim_500)),
                         lwr = quantile(c_across(sim_1:sim_500), 0.025),
                         upr = quantile(c_across(sim_1:sim_500), 0.975)) %>% 
                  select(fit, lwr, upr))
```

### -- Slight segue

With standard linear regression model (first used), we used `predict` to generate a 'prediction interval'. With linear mixed effects models, we do no have the same function available (that will incorporate the random effects variability into the prediction interval), so rather than calculating these with a formula, we simulate! Some extra content on this can be read [here](https://tmalsburg.github.io/predict-vs-simulate.html) or [(somewhat less so) here](https://stackoverflow.com/questions/63198626/predictinterval-and-the-which-option).

This use of simulation is part of the reason behind the confidence intervals not being parallel.

## Back to our Mixed effects model

```{r echo=T, fig.align='center', fig.width=10, fig.height=5}
p_mod2 %>% 
  ggplot(aes(t, fit, ymin = lwr, ymax = upr, fill = gender)) +
  geom_ribbon(alpha = 0.5) +
  geom_line(colour = "black", linewidth = 1) + 
  facet_wrap(~ gender) +
  scale_fill_viridis_d(option = "viridis", end = 0.4) +
  theme_clean() +
  theme(legend.position="none") +
  labs(x = "Time (years)", y = "Wage (logged)") +
  coord_cartesian(xlim = c(0,7),
                  ylim = c(4.5,9)) -> p2
p2
```

When we compare the output of this model with the earlier (erroneous) model, we see two expected things.

```{r echo = T}
export_summs(mod1, mod2,
             error_format = "[{conf.low}, {conf.high}]",
             error_pos = "right", digits = 3,
             statistics = c(N = "nobs"),
             model.names = c("Erroneous model", "Mixed efects model"))
```

-   The coefficients have the same value in each model as these represent the fixed effect
-   The confidence intervals for those coefficients are slightly narrower in Model 2, this is because some of the variation present \[within Model 1\] is explained by the random effects \[present in Model 2 and not Model 1\].

We can see this when we plot the predicted values side by side.

```{r echo=T, fig.align='center', fig.width=10, fig.height=12}
(p1 + labs(title = "Erroneous model")) / (p2 + labs(title = "Mixed effects model"))
```

# Introduction of missing data

We now create a modified copy of the dataset whereby ***wage data is missing as a function of the previous wage value***.

That is, as a person's wage gets higher, their probability of not completing the following years survey is increased. I was unable to implement the exact same missing data function as the [inspiring example](https://statisticalhorizons.com/wp-content/uploads/MissingDataByML.pdf), but the below is similar and serves the same purpose. Without diving too far down the missing data hole (intended), this is an example of data \[missing at random\](https://www.ncbi.nlm.nih.gov/books/NBK493614/#:\~:text=Missing%20completely%20at%20random%20(MCAR,and%20those%20with%20complete%20data), in the fact that the data missing is related to [something observed]{.underline} (by design), that being, the previous years wage value.

```{r echo=T}
mdat <- dat %>% 
  group_by(id) %>% 
  mutate(plwage = c(0, lwage[1:6]),
         pt = 1 / (1+exp(-6.9 + plwage)),
         mlwage = case_when(pt > 0.5 ~ lwage,
                           pt < 0.5 ~ 0),
         is_zero_following = ifelse(mlwage == 0, 1, 0),
         # Use cummax to make this vector 1 from the first occurrence of 0 onwards
         is_zero_following = cummax(is_zero_following),
         # Replace wage with 0 where is_zero_following is 1
         mlwage = ifelse(is_zero_following == 1, NA, mlwage)) 
```

What impact has this had on the data? We can see a significant loss of data, especially across the latter years.

```{r echo = F, eval = F}
mdat %>% 
  ungroup() %>% 
  select(gender, t) %>% 
  tbl_summary(by = gender,
              statistic = all_categorical() ~ "{n}")
```

This also looks to have impacted males more than females.

```{r echo = F, eval = F}
mdat %>% 
  ungroup() %>% 
  filter(!is.na(mlwage)) %>% 
  select(gender, t) %>% 
  tbl_summary(by = gender,
              statistic = all_categorical() ~ "{n}")
```

```{r echo=T}
mdat %>% 
  filter(!is.na(mlwage)) %>% 
  mutate(missing = "After") %>%
  rbind(
    mdat %>% mutate(missing = "Before")
  ) %>%
  mutate(missing = factor(missing, levels = c("Before", "After"))) %>%
  ungroup() %>%
  select(gender, t, missing) %>%
  tbl_strata(
    strata = missing,
    .tbl_fun = ~ .x %>%
      tbl_summary(by = gender,
                  statistic = all_categorical() ~ "{n}")
  )
```

Visually, our data now looks like this:

```{r echo=T, fig.align='center', fig.width=10, fig.height=5, warning=FALSE, message=FALSE}
mdat %>% 
  ggplot(aes(t, mlwage, colour = gender)) +
  geom_point(alpha = 0.15) +
  geom_line(aes(group = id), alpha = 0.15) + 
  facet_wrap(~ gender) +
  scale_colour_viridis_d(option = "viridis", end = 0.4) +
  theme_clean() +
  theme(legend.position="none") +
  labs(x = "Time (years)", y = "Wage (logged)")  +
  coord_cartesian(xlim = c(0,7),
                  ylim = c(4.5,9)) 
```

What is missing?

```{r echo=T, fig.align='center', fig.width=10, fig.height=5, warning=FALSE, message=FALSE}
mdat %>% 
  ggplot(aes(t, mlwage, colour = gender)) +
  geom_point(data = mdat %>% filter(is_zero_following == 1),
             aes(y = lwage, group = id), alpha = 0.1, colour = "red") +
  geom_line(data = mdat %>% filter(is_zero_following == 1),
            aes(y = lwage, group = id), alpha = 0.15, colour = "red") + 
  geom_point(alpha = 0.15) +
  geom_line(aes(group = id), alpha = 0.15) + 
  facet_wrap(~ gender) +
  scale_colour_viridis_d(option = "viridis", end = 0.4) +
  theme_clean() +
  theme(legend.position="none",
        plot.subtitle=element_text(colour = "red")) +
  labs(x = "Time (years)", y = "Wage (logged)",
       subtitle = "Missing data shown in red")  +
  coord_cartesian(xlim = c(0,7),
                  ylim = c(4.5,9))
```

## Missing - Erroneous basic linear regression model

```{r echo = T}
mod3 <- lm(mlwage ~ gender * t, data = mdat)
export_summs(mod3, error_format = "[{conf.low}, {conf.high}]",
             error_pos = "right", digits = 3,
             statistics = c(N = "nobs"))
```

Now the model is indicating that there is a strong interaction effect for gender by time. The coefficient of the interaction term implies that (logged) wages increase at a faster rate (over time) for females than they do for males.

Let's visual this alongside our modified dataset.

```{r echo = T}
newdat <- expand.grid(t = 1:7, gender = c("Male", "Female"), id = 1) %>% 
  mutate(gender = factor(gender),
         gender = relevel(gender, "Male"))

p_mod3 <- cbind(newdat, 
                lwage = predict(mod3, newdat, interval = "prediction"))
```

```{r echo=T, fig.align='center', fig.width=10, fig.height=5, warning=F, message=F}
mdat %>% 
  ggplot(aes(t, mlwage, colour = gender)) +
  geom_ribbon(data = p_mod3, aes(t, lwage.fit, ymin = lwage.lwr, ymax = lwage.upr, fill = gender), alpha = 0.5) +
  geom_line(data = p_mod3, aes(t, lwage.fit), colour = "black", linewidth = 1) + 
  geom_point(data = mdat %>% filter(is_zero_following == 1),
             aes(y = lwage, group = id), alpha = 0.1, colour = "red") +
  geom_line(data = mdat %>% filter(is_zero_following == 1),
            aes(y = lwage, group = id), alpha = 0.15, colour = "red") + 
  geom_point(alpha = 0.15) +
  geom_line(aes(group = id), alpha = 0.15) + 
  facet_wrap(~ gender) +
  scale_colour_viridis_d(option = "viridis", end = 0.4) +
  theme_clean() +
  theme(legend.position="none",
        plot.subtitle=element_text(colour = "red")) +
  labs(x = "Time (years)", y = "Wage (logged)",
       subtitle = "Missing data shown in red")  +
  coord_cartesian(xlim = c(0,7),
                  ylim = c(4.5,9)) -> p4
p4
```

We can see the predicted line and bands (95% prediction interval) represent the ([**non-missing**]{.underline}) data well, and we can see the difference in slope between genders - the observed significant interaction term.

## Missing - Mixed effects model

```{r echo = T}
mod4 <- lmer(mlwage ~ gender * t + (1 | id), data = mdat)
export_summs(mod4, error_format = "[{conf.low}, {conf.high}]",
             error_pos = "right", digits = 3,
             statistics = c(N = "nobs"))
```

When we run the mixed effects model on the dataset with missing data, we (correctly) *do not* see a significant interaction effect.

In fact:

```{r echo = T}
export_summs(mod4, mod2,
             error_format = "[{conf.low}, {conf.high}]",
             error_pos = "right", digits = 3,
             model.names = c("ME - Missing", "ME - Complete"),
             statistics = c(N = "nobs"))
```

Our mixed effects model on the dataset with a lot of missing data (ME - Missing) generates quite similar estimates to what we know the 'truth' to be from the model on the complete data (ME - Complete).

To comparatively visualise this.

```{r echo = T}
newdat <- expand.grid(t = 1:7, gender = c("Male", "Female")) %>% 
  mutate(gender = factor(gender),
         gender = relevel(gender, "Male"),
         id = c(rep(4, 7), rep(8, 7)))

store <- simulate(mod4, seed=1, newdata=newdat, re.form=NA,
                  allow.new.levels=T, nsim = 500)

p_mod4 <- cbind(newdat,
                store %>% 
                  rowwise() %>% 
                  mutate(fit = mean(c_across(sim_1:sim_500)),
                         lwr = quantile(c_across(sim_1:sim_500), 0.025),
                         upr = quantile(c_across(sim_1:sim_500), 0.975)) %>% 
                  select(fit, lwr, upr))
```

```{r echo=T, fig.align='center', fig.width=10, fig.height=5, warning=FALSE, message=FALSE}
mdat %>% 
  ggplot(aes(t, mlwage, colour = gender)) +
  geom_ribbon(data = p_mod4, aes(t, fit, ymin = lwr, ymax = upr, fill = gender), alpha = 0.5) +
  geom_line(data = p_mod4, aes(t, fit), colour = "black", linewidth = 1) + 
  geom_point(data = mdat %>% filter(is_zero_following == 1),
             aes(y = lwage, group = id), alpha = 0.1, colour = "red") +
  geom_line(data = mdat %>% filter(is_zero_following == 1),
            aes(y = lwage, group = id), alpha = 0.15, colour = "red") + 
  geom_point(alpha = 0.15) +
  geom_line(aes(group = id), alpha = 0.15) + 
  facet_wrap(~ gender) +
  scale_colour_viridis_d(option = "viridis", end = 0.4) +
  theme_clean() +
  theme(legend.position="none",
        plot.subtitle=element_text(colour = "red")) +
  labs(x = "Time (years)", y = "Wage (logged)",
       subtitle = "Missing data shown in red")  +
  coord_cartesian(xlim = c(0,7),
                  ylim = c(4.5,9)) -> p4
p4
```

These lines (predicted lines; by gender) look parallel (as they should). Notably with the Males, we see the predicted line "pulled up" in the direction of the missing data even though that data was not available to the model - this is because the model has leveraged the slope of the data it did have access to, at the individual (person) level, when converging on its estimates.

If the erroneous interaction effect (non-parallel lines) was not obvious in the plot separated by gender, here we see the predicted lines on the same plot for each model.

```{r echo=T, fig.align='center', fig.width=10, fig.height=5, warning=FALSE, message=FALSE}
p_mod3 %>% 
  ggplot(aes(t, lwage.fit, ymin = lwage.lwr, ymax = lwage.upr, fill = gender)) +
  geom_ribbon(alpha = 0.5) +
  geom_line(colour = "black", linewidth = 1) + 
  scale_fill_viridis_d(option = "viridis", end = 0.4) +
  theme_clean() +
  labs(x = "Time (years)", y = "Wage (logged)",
       title = "Erroneous basic linear regression",
       subtitle = "Missing data present") +
  coord_cartesian(xlim = c(0,7),
                  ylim = c(4.5,9)) -> p5

p_mod4 %>% 
  ggplot(aes(t, fit, ymin = lwr, ymax = upr, fill = gender)) +
  geom_ribbon(alpha = 0.5) +
  geom_line(colour = "black", linewidth = 1) + 
  scale_fill_viridis_d(option = "viridis", end = 0.4) +
  theme_clean() +
  labs(x = "Time (years)", y = "Wage (logged)",
       title = "Mixed effects regression",
       subtitle = "Missing data present")  +
  coord_cartesian(xlim = c(0,7),
                  ylim = c(4.5,9)) -> p6

p5 + p6 + plot_layout(guides = "collect") & theme(legend.position='bottom')
```

# Bonus content

## Less aggressive missingness

What if we whip through the same process and comparison, in a setting that 'less aggressively' has drop out with increasing wage and also some additional random missingness throughout.

```{r echo = T}
mdat <- dat %>% 
  group_by(id) %>% 
  mutate(plwage = c(0, lwage[1:6]),
         pt = 1 / (1+exp(-7.2 + plwage))) %>% # Less aggressive dropout as a function of age
  rowwise() %>% 
  mutate(pt = case_when(pt > 0.5 & runif(1) < 0.10 & t > 2 ~ 0, # Adding an underlying random component to dropout
                        T ~ pt)) %>% 
  group_by(id) %>% 
  mutate(mlwage = case_when(pt > 0.5 ~ lwage,
                            pt < 0.5 ~ 0),
         is_zero_following = ifelse(mlwage == 0, 1, 0),
         is_zero_following = cummax(is_zero_following),
         mlwage = ifelse(is_zero_following == 1, NA, mlwage)) 
```

```{r echo=FALSE}
mdat %>% 
  ungroup() %>% 
  filter(!is.na(mlwage)) %>% 
  select(gender, t) %>% 
  tbl_summary(by = gender,
              statistic = all_categorical() ~ "{n}")
```

```{r echo=T, fig.align='center', fig.width=10, fig.height=5, warning=FALSE, message=FALSE}
mdat %>% 
  ggplot(aes(t, mlwage, colour = gender)) +
  geom_point(data = mdat %>% filter(is_zero_following == 1),
             aes(y = lwage, group = id), alpha = 0.1, colour = "red") +
  geom_line(data = mdat %>% filter(is_zero_following == 1),
            aes(y = lwage, group = id), alpha = 0.15, colour = "red") + 
  geom_point(alpha = 0.15) +
  geom_line(aes(group = id), alpha = 0.15) + 
  facet_wrap(~ gender) +
  scale_colour_viridis_d(option = "viridis", end = 0.4) +
  theme_clean() +
  theme(legend.position="none") +
  labs(x = "Time (years)", y = "Wage (logged)")  +
  coord_cartesian(xlim = c(0,7),
                  ylim = c(4.5,9))
```

```{r echo = T}
b1_mod1 <- lm(mlwage ~ gender * t, data = mdat)
b1_mod2 <- lmer(mlwage ~ gender * t + (1 | id), data = mdat)

export_summs(mod2, b1_mod1, b1_mod2,
             error_format = "[{conf.low}, {conf.high}]",
             error_pos = "right", digits = 3,
             model.names = c("ME - Complete", "Basic - Missing", "ME - Missing"),
             statistics = c(N = "nobs"))
```

We can see, the (erroneous) basic linear regression still inappropriately suggests a significant interaction effect is present, while the mixed effects models continues to perform well (relative to the model using the complete data).

## Completely random missingness

What if the dropout is completely at random?

Note, this is [**dropout**]{.underline} at random, not [**sporadic missingness**]{.underline}, these are two different things.

```{r echo = T}
mdat <- dat %>% 
  group_by(id) %>% 
  rowwise() %>% 
  mutate(pt = 1,
         pt = case_when(runif(1) < 0.10 & t > 2 ~ 0, # Implementing completely random dropout
                        T ~ pt)) %>% 
  group_by(id) %>% 
  mutate(mlwage = case_when(pt > 0.5 ~ lwage,
                            pt < 0.5 ~ 0),
         is_zero_following = ifelse(mlwage == 0, 1, 0),
         is_zero_following = cummax(is_zero_following),
         mlwage = ifelse(is_zero_following == 1, NA, mlwage)) 
```

```{r echo=FALSE, fig.align='center', fig.width=10, fig.height=5, warning=FALSE, message=FALSE}
mdat %>% 
  ggplot(aes(t, mlwage, colour = gender)) +
  geom_point(data = mdat %>% filter(is_zero_following == 1),
             aes(y = lwage, group = id), alpha = 0.1, colour = "red") +
  geom_line(data = mdat %>% filter(is_zero_following == 1),
            aes(y = lwage, group = id), alpha = 0.15, colour = "red") + 
  geom_point(alpha = 0.15) +
  geom_line(aes(group = id), alpha = 0.15) + 
  facet_wrap(~ gender) +
  scale_colour_viridis_d(option = "viridis", end = 0.4) +
  theme_clean() +
  theme(legend.position="none") +
  labs(x = "Time (years)", y = "Wage (logged)")  +
  coord_cartesian(xlim = c(0,7),
                  ylim = c(4.5,9))
```

```{r echo = F}
b2_mod1 <- lm(mlwage ~ gender * t, data = mdat)
b2_mod2 <- lmer(mlwage ~ gender * t + (1 | id), data = mdat)

export_summs(mod2, b2_mod1, b2_mod2,
             error_format = "[{conf.low}, {conf.high}]",
             error_pos = "right", digits = 3,
             model.names = c("ME - Complete", "Basic - Missing", "ME - Missing"),
             statistics = c(N = "nobs"))
             
```

The basic regression model is no long suggesting there is a significant gender by time interaction effect, and comparatively, all three models give similar estimates.

# Conclusion

We have seen that in the face of missing follow-up data, it is a grave mistake to continue with a basic linear regression model. We have then seen that mixed effects models are quite robust in dealing with the issue of missing data (as it relates to drop out) and return coefficients and standard errors similar to those of a complete-data model.

## Acknowledgements

Thanks to Elizabeth McKinnon, Zac Dempsey, and Wesley Billingham for providing feedback on and reviewing this post.

You can look forward to seeing posts from these other team members here in the coming weeks and months.

## Reproducibility Information

To access the .qmd (Quarto markdown) files as well as any R scripts or data that was used in this post, please visit our GitHub:

<https://github.com/The-Kids-Biostats/The-Kids-Biostats.github.io/tree/main/posts/lmer-missingx>

The session information can also be seen below.

```{r}
sessionInfo()
```
