---
title: "Analysing Pre-Post data"
format:
  html:
    code-fold: true
    toc: true
    toc-location: left
date: "2024-06-07"
author: "Dr Matthew Cooper"
categories:
  - Missing Data
  - Mixed Models
  - R
draft: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F, warning = F)

library(lme4); library(merTools); library(AER)
library(gtsummary); library(jtools); library(parameters)
library(patchwork); library(tidyverse); library(data.table)

theme_clean <- function() {
  theme_minimal(base_family = "Barlow Semi Condensed") +
    theme(panel.grid.minor = element_blank(),
          plot.title = element_text(family = "BarlowSemiCondensed-Bold"),
          axis.title = element_text(family = "BarlowSemiCondensed-Medium"),
          strip.text = element_text(family = "BarlowSemiCondensed-Bold",
                                    size = rel(1), hjust = 0),
          strip.background = element_rect(fill = "grey80", color = NA))
}
```

# Overview

Pre-post designs are in use everywhere we look. Before and after treatment, e.g. in a randomised clinical trial, might be the example most readily comes to mind for analysts in the health sciences area. However, the pre-post concept occurs in many non-randomised settings as well, like observational studies or retrospective policy evaluation studies, and can feature in our daily lives without use even knowing it (like in A/B testing to see if you spend just a little bit longer on social media).

While in principle, the set-up (premise) for such a question seems straight forward, there is extensive literature debating the different approaches to the analysis of data structured this way. The discussions around these choices may confuse the lay or even semi-experienced analyst reader. Often these discussions are held without a serviceable example to illustrate implementation.

So, here we go.

# Analysis options

When we have pre-post data (focusing on continuous, approximately normally distributed data here), there three approaches analysts may reach for:

-   **change score analysis**
    -   the outcome variable for each case is reduced one data point ('post value' - 'pre value')
    -   can be analysed as the outcome variable of a linear regression model with the treatment variable as the exposure of interest (on the right hand side (RHS) of the model)
    -   can just be analysed via a T-test
-   **linear regression**
    -   the data is structured as one row per case, with two variables representation the outcome (one for pre, one for post)
    -   the outcome variable is the post measurement with the treatment variable as the exposure of interest (RHS of the model)
    -   i\) ANCOVA framework, with the outcome variable is the post measurement, the treatment variable as the exposure of interest, and the pre measurement as an adjustment variable **\[typically, this is the recommended way to analyse pre-post data\]\***
-   **linear mixed effects models**
    -   can be structured in the same way as linear regression, via an ANCOVA framework (and this will reduce to linear regression in certain situations, OR
    -   ii\) the data is structured as two rows per case, with one variable representing the outcome, with one row for the pre measurement and one row for the post measurement (here, in a sense, pre-post represents a time variable)
        -   then, both the pre and post measurements are on the left hand side (LHS) of the model, with the treatment variable as the exposure of interest and the 'time variable' on the RHS of the model)

*\*typically, statisticians are very reserved about making broad sweeping methodological recommendations, typically - I share that reservation, but pragmatically speaking, ANCOVA is typically the go to for a lot of analysts in a lot of pre-post scenarios.*

We are really going to focus on i and ii as labelled above.

# Setting the scene

We're going to use some simulated data here, generated using the [`simstudy`](https://cran.r-project.org/web/packages/simstudy/index.html) package.

We generate a dataset based on the following:

-   data for 204 treatment patients
    -   Pre data has a mean of 20, post data has a mean of 50
    -   Both have an SD of 7.5
-   data for 197 control patients
    -   Pre data has a mean of 10, post data has a mean of 20
    -   Both have an SD of 5
-   pre data is measured between days (time) 0 to 28 \[largely ignored\]
-   post data is measured between days (time) 150 and 210 \[largely ignored\]
-   there is no inforced relationship between an individuals pre and post measurements (in general they all go up, but it's noisy)

For full readability, we do this in four steps, and then combine. Let's have a look.

```{r}
# Initialize random seed for reproducibility
set.seed(2024)

# Generate Treatment group data
dtTreatPre <- data.table(id = 1:204, group = "Treatment", time = sample(0:28, 204, replace = TRUE), 
                         Out = rnorm(204, mean = 20, sd = 7.5), timepoint = "Pre")
dtTreatPost <- data.table(id = 1:204, group = "Treatment", time = sample(150:210, 204, replace = TRUE), 
                          Out = dtTreatPre$Out + rnorm(204, mean = 50, sd = 7.5), timepoint = "Post")

# Generate Control group data
dtControlPre <- data.table(id = 205:401, group = "Control", time = sample(0:28, 197, replace = TRUE), 
                           Out = pmax(rnorm(197, mean = 10, sd = 5), 0), timepoint = "Pre")
dtControlPost <- data.table(id = 205:401, group = "Control", time = sample(150:210, 197, replace = TRUE), 
                            Out = dtControlPre$Out + rnorm(197, mean = 20, sd = 5), timepoint = "Post")

# Combine data
dat <- rbind(dtTreatPre, dtTreatPost, dtControlPre, dtControlPost)
```

```{r}
dat
```

```{r}
dat %>% 
  mutate(timepoint = factor(timepoint, levels = c("Pre", "Post"))) %>% 
  group_by(group, timepoint) %>% 
  summarise(`Group Means` = mean(Out),
            `Group SDs` = sd(Out))
```

### Some visuals of our data

```{r echo=T, fig.align='center', fig.width=10, fig.height=5}
#dat %>% 
#  ggplot(aes(t, lwage, colour = gender)) +
#  geom_point(alpha = 0.15) +
#  geom_line(aes(group = id), alpha = 0.15) + 
#  facet_wrap(~ gender) +
#  scale_colour_viridis_d(option = "viridis", end = 0.4) +
#  theme_clean() +
#  theme(legend.position="none") +
#  labs(x = "Time (years)", y = "Wage (logged)") +
#  coord_cartesian(xlim = c(0,7),
#                  ylim = c(4.5,9))
```

## Research question

Are there differences in the rate of wage growth between males and females over time (in this dataset)?

That question is quite straightforward to answer here, but the motivating commentary is really around how mixed effects model can be beneficial in the presence of systematic missing (follow-up) data - with a focus on parameter estimates and their graphical interpretation.

Missing follow-up data (lost to follow, attrition, drop out) is often seen in health research datasets. The data might be Missing At Random, it my be Missing Completely At Random, the important nuances of these are largely out of scope for this post.

# Conclusion

We have seen that in the face of missing follow-up data, it is a grave mistake to continue with a basic linear regression model. We have then seen that mixed effects models are quite robust in dealing with the issue of missing data (as it relates to drop out) and return coefficients and standard errors similar to those of a complete-data model.

## Acknowledgements

Thanks to Elizabeth McKinnon, Zac Dempsey, and Wesley Billingham for providing feedback on and reviewing this post.

You can look forward to seeing posts from these other team members here in the coming weeks and months.

## Reproducibility Information

To access the .qmd (Quarto markdown) files as well as any R scripts or data that was used in this post, please visit our GitHub:

<https://github.com/The-Kids-Biostats/The-Kids-Biostats.github.io/tree/main/posts/lmer-missingx>

The session information can also be seen below.

```{r}
sessionInfo()
```
