[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "We are members of the biostatistics team at Telethon Kids Institute in Perth, Western Australia. Our work involves providing statistical consultation and collaboration to child health researchers at all stages of the scientific pipeline, from design to analysis to publication.\n\nPrimarily R users, we encounter particular coding, methodology, or analysis challenges - often that have recurring or related themes. The idea of this site is to be a centralised repository of our solutions to or narration of these recurrent challenges, for both our reference and yours!\nWe hope you’ll find something useful here, and are always open to feedback and conversation on these topics."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "The Kids Biostats",
    "section": "",
    "text": "Handling Missing Data with LMER\n\n\n\n\n\n\nMissing Data\n\n\nMixed Models\n\n\nR\n\n\n\n\n\n\n\n\n\nJun 7, 2024\n\n\nDr Matthew Cooper\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/lmer-missing/index.html",
    "href": "posts/lmer-missing/index.html",
    "title": "Handling Missing Data with LMER",
    "section": "",
    "text": "As consultant statisticians, we are often approached by people who have already carried out some preliminary data analysis and who are now looking to move onto something more complex. As missing data is generally present (or rather not present!) in health-related datasets, we find this is a question that is regularly raised:\n“Can we use mixed models, since they use all available data?”\nWorking through even the basics on this topic will mean one will also have to work through challenging and varied (often cryptic) statistical nomenclature. This post is a worked example and was motivated by reading this paper. It has an interesting example of ‘missing data and mixed models’ that we thought could benefit from some figures and commentary to aid in the understanding of what is achieved."
  },
  {
    "objectID": "posts/lmer-missing/index.html#research-question",
    "href": "posts/lmer-missing/index.html#research-question",
    "title": "Handling Missing Data with LMER",
    "section": "Research question",
    "text": "Research question\nAre there differences in the rate of wage growth between males and females over time (in this dataset)?\nThat question is quite straightforward to answer here, but the motivating commentary is really around how mixed effects model can be beneficial in the presence of systematic missing (follow-up) data - with a focus on parameter estimates and their graphical interpretation.\nMissing follow-up data (lost to follow, attrition, drop out) is often seen in health research datasets. The data might be Missing At Random, it my be Missing Completely At Random, the important nuances of these are largely out of scope for this post."
  },
  {
    "objectID": "posts/lmer-missing/index.html#erroneous-basic-linear-regression-model",
    "href": "posts/lmer-missing/index.html#erroneous-basic-linear-regression-model",
    "title": "Handling Missing Data with LMER",
    "section": "Erroneous basic linear regression model",
    "text": "Erroneous basic linear regression model\nTo address the question of “are there differences between genders in the rate of wage growth”, we are going to fit a gender by time interaction term which will give us an indication of if ‘as time changes’ whether the outcome (logged wage) changes at a different rate for each gender.\n\n\nCode\nmod1 &lt;- lm(lwage ~ gender * t, data = dat)\nexport_summs(mod1, error_format = \"[{conf.low}, {conf.high}]\",\n             error_pos = \"right\", digits = 3,\n             statistics = c(N = \"nobs\"))\n\n\n\n\nModel 1\n\n(Intercept)6.340 ***[6.312, 6.368]\n\ngenderFemale-0.456 ***[-0.540, -0.372]\n\nt0.097 ***[0.091, 0.104]\n\ngenderFemale:t-0.005    [-0.024, 0.014]\n\nN4165             \n\n *** p &lt; 0.001;  ** p &lt; 0.01;  * p &lt; 0.05.\n\n\n\n\nWe can see there is an effect of gender present, and an effect of time (the growth overtime we saw in the original plot), but the very small beta coefficient (relative to the scale of data we are working with) and the p-value of 0.6 are suggestive that the rate of wage growth over time does not differ significantly between genders.\nTo view this, we’re not going to use geom_smooth or stat_summary as we might do when graphing on-the-fly, rather we will use the predict() function to create data for our line of best fit.\nTo set a coding framework which we’ll use again later in the post, we’ll create a new dataset and use predictions to draw our (straight) line.\n\n\nCode\nnewdat &lt;- expand.grid(t = 1:7, gender = c(\"Male\", \"Female\")) %&gt;% \n  mutate(gender = factor(gender),\n         gender = relevel(gender, \"Male\"))\n\np_mod1 &lt;- cbind(newdat, \n                lwage = predict(mod1, newdat, interval = \"prediction\"))\n\n\n\n\nCode\ndat %&gt;% \n  ggplot(aes(t, lwage, colour = gender)) +\n  geom_point(alpha = 0.15) +\n  geom_line(aes(group = id), alpha = 0.15) + \n  facet_wrap(~ gender) +\n  geom_line(data = p_mod1, aes(y = lwage.fit), colour = \"red\", linewidth = 1) +\n  scale_colour_viridis_d(option = \"viridis\", end = 0.4) +\n  theme_clean() +\n  theme(legend.position=\"none\") +\n  labs(x = \"Time (years)\", y = \"Wage (logged)\") +\n  coord_cartesian(xlim = c(0,7),\n                  ylim = c(4.5,9))\n\n\n\n\n\n\n\n\n\nOkay, these red fitted lines look like quite good as a ‘line of best fit’; they pass the eye test of broadly representing the trends of the data well.\nFitted with a prediction confidence interval, we see.\n\n\nCode\np_mod1 %&gt;% \n  ggplot(aes(t, lwage.fit, ymin = lwage.lwr, ymax = lwage.upr, fill = gender)) +\n  geom_ribbon(alpha = 0.5) +\n  geom_line(colour = \"black\", linewidth = 1) + \n  facet_wrap(~ gender) +\n  scale_fill_viridis_d(option = \"viridis\", end = 0.4) +\n  theme_clean() +\n  theme(legend.position=\"none\") +\n  labs(x = \"Time (years)\", y = \"Wage (logged)\")  +\n  coord_cartesian(xlim = c(0,7),\n                  ylim = c(4.5,9)) -&gt; p1\np1\n\n\n\n\n\n\n\n\n\nThese lines look parallel - suggestive of no difference in growth rates between the genders (in line with the non-significant interaction term we saw).\nOf course, we have not adjusted for the within person correlation present in the data. The model above is inappropriate as one of the main assumptions of the model is violated - the data points are not all independent (we know there are 7 from each individual)."
  },
  {
    "objectID": "posts/lmer-missing/index.html#mixed-effects-model",
    "href": "posts/lmer-missing/index.html#mixed-effects-model",
    "title": "Handling Missing Data with LMER",
    "section": "Mixed effects model",
    "text": "Mixed effects model\nHere we run a fairly basic linear mixed effects model, the model has the same fixed effects terms as above (the interaction term we are curious about) but also includes a random effect, that is, the intercept is allowed to varied for each individual.\n\n\nCode\nmod2 &lt;- lmer(lwage ~ gender * t + (1 | id), data = dat)\nexport_summs(mod2, error_format = \"[{conf.low}, {conf.high}]\",\n             error_pos = \"right\", digits = 3,\n             statistics = c(N = \"nobs\"))\n\n\n\n\nModel 1\n\n(Intercept)6.340 ***[6.307, 6.373]\n\ngenderFemale-0.456 ***[-0.553, -0.358]\n\nt0.097 ***[0.095, 0.100]\n\ngenderFemale:t-0.005    [-0.012, 0.003]\n\nN4165             \n\n *** p &lt; 0.001;  ** p &lt; 0.01;  * p &lt; 0.05.\n\n\n\n\nLets also fit the predicted values from this model.\n\n\nCode\nnewdat &lt;- expand.grid(t = 1:7, gender = c(\"Male\", \"Female\")) %&gt;% \n  mutate(gender = factor(gender),\n         gender = relevel(gender, \"Male\"),\n         id = c(rep(1, 7), rep(2, 7)))\n\nstore &lt;- simulate(mod2, seed=1, newdata=newdat, re.form=NA,\n                  allow.new.levels=T, nsim = 500)\n\np_mod2 &lt;- cbind(newdat,\n                store %&gt;% \n                  rowwise() %&gt;% \n                  mutate(fit = mean(c_across(sim_1:sim_500)),\n                         lwr = quantile(c_across(sim_1:sim_500), 0.025),\n                         upr = quantile(c_across(sim_1:sim_500), 0.975)) %&gt;% \n                  select(fit, lwr, upr))\n\n\n\n– Slight segue\nWith standard linear regression model (first used), we used predict to generate a ‘prediction interval’. With linear mixed effects models, we do no have the same function available (that will incorporate the random effects variability into the prediction interval), so rather than calculating these with a formula, we simulate! Some extra content on this can be read here or (somewhat less so) here.\nThis use of simulation is part of the reason behind the confidence intervals not being parallel."
  },
  {
    "objectID": "posts/lmer-missing/index.html#back-to-our-mixed-effects-model",
    "href": "posts/lmer-missing/index.html#back-to-our-mixed-effects-model",
    "title": "Handling Missing Data with LMER",
    "section": "Back to our Mixed effects model",
    "text": "Back to our Mixed effects model\n\n\nCode\np_mod2 %&gt;% \n  ggplot(aes(t, fit, ymin = lwr, ymax = upr, fill = gender)) +\n  geom_ribbon(alpha = 0.5) +\n  geom_line(colour = \"black\", linewidth = 1) + \n  facet_wrap(~ gender) +\n  scale_fill_viridis_d(option = \"viridis\", end = 0.4) +\n  theme_clean() +\n  theme(legend.position=\"none\") +\n  labs(x = \"Time (years)\", y = \"Wage (logged)\") +\n  coord_cartesian(xlim = c(0,7),\n                  ylim = c(4.5,9)) -&gt; p2\np2\n\n\n\n\n\n\n\n\n\nWhen we compare the output of this model with the earlier (erroneous) model, we see two expected things.\n\n\nCode\nexport_summs(mod1, mod2,\n             error_format = \"[{conf.low}, {conf.high}]\",\n             error_pos = \"right\", digits = 3,\n             statistics = c(N = \"nobs\"),\n             model.names = c(\"Erroneous model\", \"Mixed efects model\"))\n\n\n\n\nErroneous modelMixed efects model\n\n(Intercept)6.340 ***[6.312, 6.368]6.340 ***[6.307, 6.373]\n\ngenderFemale-0.456 ***[-0.540, -0.372]-0.456 ***[-0.553, -0.358]\n\nt0.097 ***[0.091, 0.104]0.097 ***[0.095, 0.100]\n\ngenderFemale:t-0.005    [-0.024, 0.014]-0.005    [-0.012, 0.003]\n\nN4165             4165             \n\n *** p &lt; 0.001;  ** p &lt; 0.01;  * p &lt; 0.05.\n\n\n\n\n\nThe coefficients have the same value in each model as these represent the fixed effect\nThe confidence intervals for those coefficients are slightly narrower in Model 2, this is because some of the variation present [within Model 1] is explained by the random effects [present in Model 2 and not Model 1].\n\nWe can see this when we plot the predicted values side by side.\n\n\nCode\n(p1 + labs(title = \"Erroneous model\")) / (p2 + labs(title = \"Mixed effects model\"))"
  },
  {
    "objectID": "posts/lmer-missing/index.html#missing---erroneous-basic-linear-regression-model",
    "href": "posts/lmer-missing/index.html#missing---erroneous-basic-linear-regression-model",
    "title": "Handling Missing Data with LMER",
    "section": "Missing - Erroneous basic linear regression model",
    "text": "Missing - Erroneous basic linear regression model\n\n\nCode\nmod3 &lt;- lm(mlwage ~ gender * t, data = mdat)\nexport_summs(mod3, error_format = \"[{conf.low}, {conf.high}]\",\n             error_pos = \"right\", digits = 3,\n             statistics = c(N = \"nobs\"))\n\n\n\n\nModel 1\n\n(Intercept)6.379 ***[6.354, 6.405]\n\ngenderFemale-0.462 ***[-0.533, -0.390]\n\nt0.047 ***[0.040, 0.053]\n\ngenderFemale:t0.032 ***[0.016, 0.049]\n\nN3101             \n\n *** p &lt; 0.001;  ** p &lt; 0.01;  * p &lt; 0.05.\n\n\n\n\nNow the model is indicating that there is a strong interaction effect for gender by time. The coefficient of the interaction term implies that (logged) wages increase at a faster rate (over time) for females than they do for males.\nLet’s visual this alongside our modified dataset.\n\n\nCode\nnewdat &lt;- expand.grid(t = 1:7, gender = c(\"Male\", \"Female\"), id = 1) %&gt;% \n  mutate(gender = factor(gender),\n         gender = relevel(gender, \"Male\"))\n\np_mod3 &lt;- cbind(newdat, \n                lwage = predict(mod3, newdat, interval = \"prediction\"))\n\n\n\n\nCode\nmdat %&gt;% \n  ggplot(aes(t, mlwage, colour = gender)) +\n  geom_ribbon(data = p_mod3, aes(t, lwage.fit, ymin = lwage.lwr, ymax = lwage.upr, fill = gender), alpha = 0.5) +\n  geom_line(data = p_mod3, aes(t, lwage.fit), colour = \"black\", linewidth = 1) + \n  geom_point(data = mdat %&gt;% filter(is_zero_following == 1),\n             aes(y = lwage, group = id), alpha = 0.1, colour = \"red\") +\n  geom_line(data = mdat %&gt;% filter(is_zero_following == 1),\n            aes(y = lwage, group = id), alpha = 0.15, colour = \"red\") + \n  geom_point(alpha = 0.15) +\n  geom_line(aes(group = id), alpha = 0.15) + \n  facet_wrap(~ gender) +\n  scale_colour_viridis_d(option = \"viridis\", end = 0.4) +\n  theme_clean() +\n  theme(legend.position=\"none\",\n        plot.subtitle=element_text(colour = \"red\")) +\n  labs(x = \"Time (years)\", y = \"Wage (logged)\",\n       subtitle = \"Missing data shown in red\")  +\n  coord_cartesian(xlim = c(0,7),\n                  ylim = c(4.5,9)) -&gt; p4\np4\n\n\n\n\n\n\n\n\n\nWe can see the predicted line and bands (95% prediction interval) represent the (non-missing) data well, and we can see the difference in slope between genders - the observed significant interaction term."
  },
  {
    "objectID": "posts/lmer-missing/index.html#missing---mixed-effects-model",
    "href": "posts/lmer-missing/index.html#missing---mixed-effects-model",
    "title": "Handling Missing Data with LMER",
    "section": "Missing - Mixed effects model",
    "text": "Missing - Mixed effects model\n\n\nCode\nmod4 &lt;- lmer(mlwage ~ gender * t + (1 | id), data = mdat)\nexport_summs(mod4, error_format = \"[{conf.low}, {conf.high}]\",\n             error_pos = \"right\", digits = 3,\n             statistics = c(N = \"nobs\"))\n\n\n\n\nModel 1\n\n(Intercept)6.341 ***[6.311, 6.372]\n\ngenderFemale-0.457 ***[-0.546, -0.368]\n\nt0.090 ***[0.087, 0.093]\n\ngenderFemale:t0.003    [-0.004, 0.011]\n\nN3101             \n\n *** p &lt; 0.001;  ** p &lt; 0.01;  * p &lt; 0.05.\n\n\n\n\nWhen we run the mixed effects model on the dataset with missing data, we (correctly) do not see a significant interaction effect.\nIn fact:\n\n\nCode\nexport_summs(mod4, mod2,\n             error_format = \"[{conf.low}, {conf.high}]\",\n             error_pos = \"right\", digits = 3,\n             model.names = c(\"ME - Missing\", \"ME - Complete\"),\n             statistics = c(N = \"nobs\"))\n\n\n\n\nME - MissingME - Complete\n\n(Intercept)6.341 ***[6.311, 6.372]6.340 ***[6.307, 6.373]\n\ngenderFemale-0.457 ***[-0.546, -0.368]-0.456 ***[-0.553, -0.358]\n\nt0.090 ***[0.087, 0.093]0.097 ***[0.095, 0.100]\n\ngenderFemale:t0.003    [-0.004, 0.011]-0.005    [-0.012, 0.003]\n\nN3101             4165             \n\n *** p &lt; 0.001;  ** p &lt; 0.01;  * p &lt; 0.05.\n\n\n\n\nOur mixed effects model on the dataset with a lot of missing data (ME - Missing) generates quite similar estimates to what we know the ‘truth’ to be from the model on the complete data (ME - Complete).\nTo comparatively visualise this.\n\n\nCode\nnewdat &lt;- expand.grid(t = 1:7, gender = c(\"Male\", \"Female\")) %&gt;% \n  mutate(gender = factor(gender),\n         gender = relevel(gender, \"Male\"),\n         id = c(rep(4, 7), rep(8, 7)))\n\nstore &lt;- simulate(mod4, seed=1, newdata=newdat, re.form=NA,\n                  allow.new.levels=T, nsim = 500)\n\np_mod4 &lt;- cbind(newdat,\n                store %&gt;% \n                  rowwise() %&gt;% \n                  mutate(fit = mean(c_across(sim_1:sim_500)),\n                         lwr = quantile(c_across(sim_1:sim_500), 0.025),\n                         upr = quantile(c_across(sim_1:sim_500), 0.975)) %&gt;% \n                  select(fit, lwr, upr))\n\n\n\n\nCode\nmdat %&gt;% \n  ggplot(aes(t, mlwage, colour = gender)) +\n  geom_ribbon(data = p_mod4, aes(t, fit, ymin = lwr, ymax = upr, fill = gender), alpha = 0.5) +\n  geom_line(data = p_mod4, aes(t, fit), colour = \"black\", linewidth = 1) + \n  geom_point(data = mdat %&gt;% filter(is_zero_following == 1),\n             aes(y = lwage, group = id), alpha = 0.1, colour = \"red\") +\n  geom_line(data = mdat %&gt;% filter(is_zero_following == 1),\n            aes(y = lwage, group = id), alpha = 0.15, colour = \"red\") + \n  geom_point(alpha = 0.15) +\n  geom_line(aes(group = id), alpha = 0.15) + \n  facet_wrap(~ gender) +\n  scale_colour_viridis_d(option = \"viridis\", end = 0.4) +\n  theme_clean() +\n  theme(legend.position=\"none\",\n        plot.subtitle=element_text(colour = \"red\")) +\n  labs(x = \"Time (years)\", y = \"Wage (logged)\",\n       subtitle = \"Missing data shown in red\")  +\n  coord_cartesian(xlim = c(0,7),\n                  ylim = c(4.5,9)) -&gt; p4\np4\n\n\n\n\n\n\n\n\n\nThese lines (predicted lines; by gender) look parallel (as they should). Notably with the Males, we see the predicted line “pulled up” in the direction of the missing data even though that data was not available to the model - this is because the model has leveraged the slope of the data it did have access to, at the individual (person) level, when converging on its estimates.\nIf the erroneous interaction effect (non-parallel lines) was not obvious in the plot separated by gender, here we see the predicted lines on the same plot for each model.\n\n\nCode\np_mod3 %&gt;% \n  ggplot(aes(t, lwage.fit, ymin = lwage.lwr, ymax = lwage.upr, fill = gender)) +\n  geom_ribbon(alpha = 0.5) +\n  geom_line(colour = \"black\", linewidth = 1) + \n  scale_fill_viridis_d(option = \"viridis\", end = 0.4) +\n  theme_clean() +\n  labs(x = \"Time (years)\", y = \"Wage (logged)\",\n       title = \"Erroneous basic linear regression\",\n       subtitle = \"Missing data present\") +\n  coord_cartesian(xlim = c(0,7),\n                  ylim = c(4.5,9)) -&gt; p5\n\np_mod4 %&gt;% \n  ggplot(aes(t, fit, ymin = lwr, ymax = upr, fill = gender)) +\n  geom_ribbon(alpha = 0.5) +\n  geom_line(colour = \"black\", linewidth = 1) + \n  scale_fill_viridis_d(option = \"viridis\", end = 0.4) +\n  theme_clean() +\n  labs(x = \"Time (years)\", y = \"Wage (logged)\",\n       title = \"Mixed effects regression\",\n       subtitle = \"Missing data present\")  +\n  coord_cartesian(xlim = c(0,7),\n                  ylim = c(4.5,9)) -&gt; p6\n\np5 + p6 + plot_layout(guides = \"collect\") & theme(legend.position='bottom')"
  },
  {
    "objectID": "posts/lmer-missing/index.html#less-aggressive-missingness",
    "href": "posts/lmer-missing/index.html#less-aggressive-missingness",
    "title": "Handling Missing Data with LMER",
    "section": "Less aggressive missingness",
    "text": "Less aggressive missingness\nWhat if we whip through the same process and comparison, in a setting that ‘less aggressively’ has drop out with increasing wage and also some additional random missingness throughout.\n\n\nCode\nmdat &lt;- dat %&gt;% \n  group_by(id) %&gt;% \n  mutate(plwage = c(0, lwage[1:6]),\n         pt = 1 / (1+exp(-7.2 + plwage))) %&gt;% # Less aggressive dropout as a function of age\n  rowwise() %&gt;% \n  mutate(pt = case_when(pt &gt; 0.5 & runif(1) &lt; 0.10 & t &gt; 2 ~ 0, # Adding an underlying random component to dropout\n                        T ~ pt)) %&gt;% \n  group_by(id) %&gt;% \n  mutate(mlwage = case_when(pt &gt; 0.5 ~ lwage,\n                            pt &lt; 0.5 ~ 0),\n         is_zero_following = ifelse(mlwage == 0, 1, 0),\n         is_zero_following = cummax(is_zero_following),\n         mlwage = ifelse(is_zero_following == 1, NA, mlwage)) \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nMale, N = 2,8041\nFemale, N = 3521\n\n\n\n\nt\n\n\n\n\n\n\n    1\n528\n67\n\n\n    2\n528\n67\n\n\n    3\n478\n57\n\n\n    4\n396\n49\n\n\n    5\n338\n43\n\n\n    6\n290\n38\n\n\n    7\n246\n31\n\n\n\n1 n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmdat %&gt;% \n  ggplot(aes(t, mlwage, colour = gender)) +\n  geom_point(data = mdat %&gt;% filter(is_zero_following == 1),\n             aes(y = lwage, group = id), alpha = 0.1, colour = \"red\") +\n  geom_line(data = mdat %&gt;% filter(is_zero_following == 1),\n            aes(y = lwage, group = id), alpha = 0.15, colour = \"red\") + \n  geom_point(alpha = 0.15) +\n  geom_line(aes(group = id), alpha = 0.15) + \n  facet_wrap(~ gender) +\n  scale_colour_viridis_d(option = \"viridis\", end = 0.4) +\n  theme_clean() +\n  theme(legend.position=\"none\") +\n  labs(x = \"Time (years)\", y = \"Wage (logged)\")  +\n  coord_cartesian(xlim = c(0,7),\n                  ylim = c(4.5,9))\n\n\n\n\n\n\n\n\n\n\n\nCode\nb1_mod1 &lt;- lm(mlwage ~ gender * t, data = mdat)\nb1_mod2 &lt;- lmer(mlwage ~ gender * t + (1 | id), data = mdat)\n\nexport_summs(mod2, b1_mod1, b1_mod2,\n             error_format = \"[{conf.low}, {conf.high}]\",\n             error_pos = \"right\", digits = 3,\n             model.names = c(\"ME - Complete\", \"Basic - Missing\", \"ME - Missing\"),\n             statistics = c(N = \"nobs\"))\n\n\n\n\nME - CompleteBasic - MissingME - Missing\n\n(Intercept)6.340 ***[6.307, 6.373]6.380 ***[6.352, 6.407]6.342 ***[6.311, 6.373]\n\ngenderFemale-0.456 ***[-0.553, -0.358]-0.491 ***[-0.573, -0.410]-0.465 ***[-0.557, -0.372]\n\nt0.097 ***[0.095, 0.100]0.072 ***[0.065, 0.079]0.094 ***[0.091, 0.097]\n\ngenderFemale:t-0.005    [-0.012, 0.003]0.024 *  [0.003, 0.044]0.003    [-0.006, 0.012]\n\nN4165             3156             3156             \n\n *** p &lt; 0.001;  ** p &lt; 0.01;  * p &lt; 0.05.\n\n\n\n\nWe can see, the (erroneous) basic linear regression still inappropriately suggests a significant interaction effect is present, while the mixed effects models continues to perform well (relative to the model using the complete data)."
  },
  {
    "objectID": "posts/lmer-missing/index.html#completely-random-missingness",
    "href": "posts/lmer-missing/index.html#completely-random-missingness",
    "title": "Handling Missing Data with LMER",
    "section": "Completely random missingness",
    "text": "Completely random missingness\nWhat if the dropout is completely at random?\nNote, this is dropout at random, not sporadic missingness, these are two different things.\n\n\nCode\nmdat &lt;- dat %&gt;% \n  group_by(id) %&gt;% \n  rowwise() %&gt;% \n  mutate(pt = 1,\n         pt = case_when(runif(1) &lt; 0.10 & t &gt; 2 ~ 0, # Implementing completely random dropout\n                        T ~ pt)) %&gt;% \n  group_by(id) %&gt;% \n  mutate(mlwage = case_when(pt &gt; 0.5 ~ lwage,\n                            pt &lt; 0.5 ~ 0),\n         is_zero_following = ifelse(mlwage == 0, 1, 0),\n         is_zero_following = cummax(is_zero_following),\n         mlwage = ifelse(is_zero_following == 1, NA, mlwage)) \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nME - CompleteBasic - MissingME - Missing\n\n(Intercept)6.340 ***[6.307, 6.373]6.330 ***[6.300, 6.359]6.333 ***[6.301, 6.366]\n\ngenderFemale-0.456 ***[-0.553, -0.358]-0.456 ***[-0.544, -0.368]-0.456 ***[-0.553, -0.359]\n\nt0.097 ***[0.095, 0.100]0.102 ***[0.095, 0.109]0.099 ***[0.096, 0.102]\n\ngenderFemale:t-0.005    [-0.012, 0.003]-0.007    [-0.029, 0.014]-0.003    [-0.012, 0.005]\n\nN4165             3379             3379             \n\n *** p &lt; 0.001;  ** p &lt; 0.01;  * p &lt; 0.05.\n\n\n\n\nThe basic regression model is no long suggesting there is a significant gender by time interaction effect, and comparatively, all three models give similar estimates."
  },
  {
    "objectID": "posts/lmer-missing/index.html#acknowledgements",
    "href": "posts/lmer-missing/index.html#acknowledgements",
    "title": "Handling Missing Data with LMER",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nThanks to Elizabeth McKinnon, Zac Dempsey, and Wesley Billingham for providing feedback on and reviewing this post.\nYou can look forward to seeing posts from these other team members here in the coming weeks and months."
  },
  {
    "objectID": "posts/lmer-missing/index.html#reproducibility-information",
    "href": "posts/lmer-missing/index.html#reproducibility-information",
    "title": "Handling Missing Data with LMER",
    "section": "Reproducibility Information",
    "text": "Reproducibility Information\nTo access the .qmd (Quarto markdown) files as well as any R scripts or data that was used in this post, please visit our GitHub:\nhttps://github.com/The-Kids-Biostats/The-Kids-Biostats.github.io/tree/main/posts/lmer-missingx\nThe session information can also be seen below.\n\n\nR version 4.3.3 (2024-02-29)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Sonoma 14.4.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Australia/Perth\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] lubridate_1.9.3   forcats_1.0.0     stringr_1.5.1     dplyr_1.1.4      \n [5] purrr_1.0.2       readr_2.1.5       tidyr_1.3.1       tibble_3.2.1     \n [9] ggplot2_3.5.1     tidyverse_2.0.0   patchwork_1.2.0   parameters_0.21.7\n[13] jtools_2.2.2      gtsummary_1.7.2   AER_1.2-12        survival_3.6-4   \n[17] sandwich_3.1-0    lmtest_0.9-40     zoo_1.8-12        car_3.1-2        \n[21] carData_3.0-5     merTools_0.6.2    arm_1.14-4        MASS_7.3-60.0.1  \n[25] lme4_1.1-35.3     Matrix_1.6-5     \n\nloaded via a namespace (and not attached):\n [1] rlang_1.1.3          magrittr_2.0.3       multcomp_1.4-25     \n [4] furrr_0.3.1          compiler_4.3.3       vctrs_0.6.5         \n [7] pkgconfig_2.0.3      crayon_1.5.2         fastmap_1.2.0       \n[10] backports_1.5.0      labeling_0.4.3       pander_0.6.5        \n[13] utf8_1.2.4           promises_1.3.0       rmarkdown_2.27      \n[16] markdown_1.12        tzdb_0.4.0           nloptr_2.0.3        \n[19] xfun_0.44            jsonlite_1.8.8       later_1.3.2         \n[22] broom_1.0.6          parallel_4.3.3       R6_2.5.1            \n[25] stringi_1.8.4        parallelly_1.37.1    boot_1.3-30         \n[28] numDeriv_2016.8-1.1  estimability_1.5.1   assertthat_0.2.1    \n[31] Rcpp_1.0.12          iterators_1.0.14     knitr_1.45          \n[34] httpuv_1.6.15        splines_4.3.3        timechange_0.3.0    \n[37] tidyselect_1.2.1     rstudioapi_0.16.0    abind_1.4-5         \n[40] yaml_2.3.8           codetools_0.2-20     listenv_0.9.1       \n[43] lmerTest_3.1-3       lattice_0.22-6       shiny_1.8.1.1       \n[46] withr_3.0.0          bayestestR_0.13.2    coda_0.19-4.1       \n[49] evaluate_0.23        future_1.33.2        huxtable_5.5.6      \n[52] xml2_1.3.6           pillar_1.9.0         foreach_1.5.2       \n[55] insight_0.19.11      generics_0.1.3       hms_1.1.3           \n[58] munsell_0.5.1        commonmark_1.9.1     scales_1.3.0        \n[61] minqa_1.2.7          globals_0.16.3       xtable_1.8-4        \n[64] glue_1.7.0           emmeans_1.10.2       tools_4.3.3         \n[67] mvtnorm_1.2-5        grid_4.3.3           datawizard_0.10.0   \n[70] colorspace_2.1-0     nlme_3.1-164         Formula_1.2-5       \n[73] cli_3.6.2            fansi_1.0.6          viridisLite_0.4.2   \n[76] broom.helpers_1.15.0 gt_0.10.1            gtable_0.3.5        \n[79] broom.mixed_0.2.9.5  sass_0.4.9           digest_0.6.35       \n[82] TH.data_1.1-2        farver_2.1.2         htmlwidgets_1.6.4   \n[85] htmltools_0.5.8.1    lifecycle_1.0.4      mime_0.12           \n[88] blme_1.0-5"
  }
]