{
  "hash": "a20c9957b91dde87b57fe0397cdca721",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Parallel Computing in R\"\noutput: html_document\nauthor: \"Zac Dempsey, Wes Billingham\"\ndate: \"2024-06-07\"\ncategories:\n  - R\n  - Parallel\ndraft: true\n---\n\n\n\n::: {.cell}\n\n:::\n\n\n<br>\n\n## Why Parallel Computing?\n\nWhile most of our datasets are a manageable size here at Telethon Kids Institute, there are occasions where we are suddenly presented with data containing millions of rows and hundreds if not thousands of columns. Performing almost any operation on these large datasets can take hours to execute -- a real test of patience.\n\nParallel computing is one relatively simple way to improve computation time on large datasets, by using more of your computer's resources and distributing tasks \"in parallel\" across multiple processors. This is particularly useful for loop-based computations/simulations, where one must sweep over a range of parameters/conditions and return an output. That being said, it is still worth investing the time to make sure the packages and/or functions being run are compatible with a parallel workflow.\n\n\n::: {.cell}\n\n:::\n\n\n<p>\n\n## What is Parallel Computing?\n\nParallel computing refers to allocating multiple operations in 'parallel' across a machine's multiple cores/processors. Most modern computers have at least four cores, and often vastly more. By default, R uses only one core, running iterative operations one after the other; not starting the next until the previous is complete. Under a parallel framework, multiple iterations/calculations can be allocated across multiple cores and completed at the same time -- saving time.\n\nIn this blog, we will have a look at some examples using the [`doParallel`](https://cran.r-project.org/web/packages/doParallel/) and [`foreach`](https://cran.r-project.org/web/packages/foreach/) packages in `R`. These packages together facilitate parallel computing in R. We provide some simple examples and use cases, in addition to some further resources if you would like to learn more.\n\nThese examples are run using R version 4.3.2 (2023-10-31 ucrt) on Windows 10 x64.\n\n### Resources (move to the end?)\n\n-   Vignettes\n    -   <https://cran.r-project.org/web/packages/doParallel/vignettes/gettingstartedParallel.pdf>\n-   Tutorials\n    -   <https://unc-libraries-data.github.io/R-Open-Labs/Extras/Parallel/foreach.html>\n\n<br>\n\n### Setup\n\n-   Let's check the number of cores available on our machine.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nparallel::detectCores()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 8\n```\n\n\n:::\n:::\n\n\n<p>\n\n-   We should not allocate all of our machine's available cores to parallel computations, as this will consume all of the available resources.\n-   Let's use 6 cores for our examples.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndoParallel::registerDoParallel(6)\n```\n:::\n\n\n-   Below is a screenshot from the Windows task manager. R \"front-end\" instances are initialised for each of the 6 cores.\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](parallel_comps.png){fig-align='center' width=400px}\n:::\n:::\n\n\n-   When we no longer require a parallel environment, we must shut down and de-register the parallel cluster.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndoParallel::stopImplicitCluster()\n```\n:::\n\n\n<p>\n\n## Example 1: Bootstrapping\n\n**Pre-amble about what bootstrapping is and what we use it for**\n\n-   Let's use the `mtcars` data set to run a basic linear regression.\n    -   We would like to explore the association between a vehicle's fuel efficiency (`mpg`) and horsepower (`hp`), weight (`wt`) and transmission type (automatic/manual, `am`)\n-   We suspect some of the assumptions of standard linear regression may be violated (normality of errors) because of the small sample size. By bootstrapping, we can explore the stability of the regression coefficients by calculating a confidence interval about the bootstrapped coefficient estimates.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Let's set up the data and number of bootstrap samples\ndata(mtcars)\nmtcars <- as_tibble(mtcars)\n\nhead(mtcars)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 11\n    mpg   cyl  disp    hp  drat    wt  qsec    vs    am  gear  carb\n  <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>\n1  21       6   160   110  3.9   2.62  16.5     0     1     4     4\n2  21       6   160   110  3.9   2.88  17.0     0     1     4     4\n3  22.8     4   108    93  3.85  2.32  18.6     1     1     4     1\n4  21.4     6   258   110  3.08  3.22  19.4     1     0     3     1\n5  18.7     8   360   175  3.15  3.44  17.0     0     0     3     2\n6  18.1     6   225   105  2.76  3.46  20.2     1     0     3     1\n```\n\n\n:::\n:::\n\n\n<p>\n\n-   Let's set the number of bootstrap replicates to be 1000\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntrials <- 10000 # Number of bootstrap samples\n```\n:::\n\n\n<p>\n\n### For-loop\n\n-   Let's\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(2024)\n\nstart <- proc.time()\n\n# Initialise a matrix to store the coefficients from each bootstrap sample\nbootstrap_coefs <- matrix(NA, nrow = trials, ncol = 4)\ncolnames(bootstrap_coefs) <- names(coef(lm(mpg ~ hp + wt + am, data = mtcars)))\n\nfor (i in 1:trials){\n  ind <- mtcars[sample(nrow(mtcars), replace = TRUE),]\n  result <- lm(mpg ~ hp + wt + as_factor(am), data = ind)\n  \n  bootstrap_coefs[i, ] <- coef(result)\n}\n\n# Calculate the 2.5th and 97.5th percentile for each variable's coefficient estimates from the bootstrap distribution.\nbootstrap_cis <- apply(bootstrap_coefs, 2, function(coefs){quantile(coefs, probs = c(0.025, 0.975))})\n\nend <- proc.time()\nprint(end - start)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   user  system elapsed \n  11.17    0.20   11.42 \n```\n\n\n:::\n:::\n\n\n<p>\n\n### `%do%` loop (not parallel)\n\n-   As an alternative, let's also use the `%do%` operator from the `foreach` package. Similar to a for-loop, the loop is sequentially executed.\n-   This is slightly faster than the standard for-loop execution.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstart <- proc.time()\n\nbootstrap_results <- foreach::foreach(i = 1:trials, .combine = rbind) %do% {\n  ind <- mtcars[sample(nrow(mtcars), replace = TRUE), ]\n  result <- lm(mpg ~ hp + wt + am, data = ind)\n  coef(result)\n}\n\n# Calculate the 2.5th and 97.5th percentile for each variable's coefficient estimates from the bootstrap distribution.\nbootstrap_cis <- apply(bootstrap_results, 2, function(coefs) {quantile(coefs, probs = c(0.025, 0.975))})\n\nend <- proc.time()\nprint(end - start)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   user  system elapsed \n  10.44    0.11   10.69 \n```\n\n\n:::\n:::\n\n\n<p>\n\n### `%dopar%` parallelisation\n\n-   Now, let's run this in parallel across 6 cores.\n-   The execution time is significantly reduced relative to the above two cases.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndoParallel::registerDoParallel(cores = 6)\n\nstart <- proc.time()\nbootstrap_results <- foreach(i = 1:trials, .combine = rbind, .packages = 'stats') %dopar% {\n  ind <- mtcars[sample(nrow(mtcars), replace = TRUE), ]\n  result <- lm(mpg ~ hp + wt + am, data = ind)\n  coef(result)\n}\n\n# Calculate the 2.5th and 97.5th percentile for each variable's coefficient estimates from the bootstrap distribution.\nbootstrap_cis <- apply(bootstrap_results, 2, function(coefs) {quantile(coefs, probs = c(0.025, 0.975))})\n\nend <- proc.time()\nprint(end - start)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   user  system elapsed \n   3.33    0.58    6.06 \n```\n\n\n:::\n\n```{.r .cell-code}\ndoParallel::stopImplicitCluster()\n```\n:::\n\n\n<br>\n\n## Example 2: Parallel regressions with different outcomes\n\n-   This is a situation where parallel computing may not be\n-   Let's use the `diamonds` dataset from `ggplot2`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata(diamonds)\nhead(diamonds)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 10\n  carat cut       color clarity depth table price     x     y     z\n  <dbl> <ord>     <ord> <ord>   <dbl> <dbl> <int> <dbl> <dbl> <dbl>\n1  0.23 Ideal     E     SI2      61.5    55   326  3.95  3.98  2.43\n2  0.21 Premium   E     SI1      59.8    61   326  3.89  3.84  2.31\n3  0.23 Good      E     VS1      56.9    65   327  4.05  4.07  2.31\n4  0.29 Premium   I     VS2      62.4    58   334  4.2   4.23  2.63\n5  0.31 Good      J     SI2      63.3    58   335  4.34  4.35  2.75\n6  0.24 Very Good J     VVS2     62.8    57   336  3.94  3.96  2.48\n```\n\n\n:::\n:::\n\n\n-   Outcome variables\n    -   price (USD)\n    -   carat (weight)\n-   Explanatory variables\n    -   x (length)\n    -   y (width)\n    -   z (depth)\n\n\n::: {.cell}\n\n```{.r .cell-code}\ninput_vars <- c(\"x\", \"y\", \"z\")\noutput_vars <- c(\"price\", \"carat\")\n\nformulas <- map(output_vars, ~paste(.x, \"~\", paste(input_vars, collapse = \" + \")))\n```\n:::\n\n\n<p>\n\n### For-loop\n\n\n::: {.cell}\n\n```{.r .cell-code}\nresults <- list()\n\nstart <- proc.time()\nfor (i in 1:length(formulas)){\n  formula <- formulas[[i]]\n  result <- lm(formula = formula, data = diamonds)\n  results[[ output_vars[[i]] ]] <- result\n}\nend <- proc.time()\nprint(end - start)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   user  system elapsed \n   0.01    0.02    0.03 \n```\n\n\n:::\n:::\n\n\n<p>\n\n### `purrr:map` \"parallelisation\"\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstart <- proc.time()\nresults <- map(formulas, ~{\n  lm(as.formula(.x), data = diamonds)\n})\nend <- proc.time()\nprint(end - start)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   user  system elapsed \n   0.06    0.00    0.06 \n```\n\n\n:::\n:::\n\n\n<p>\n\n### `%dopar%` parallelisation\n\n-   This probably isn't the best example to demonstrate the superior time complexity.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndoParallel::registerDoParallel(cores = 6)\n\nstart <- proc.time()\nresults <- foreach(frm = iter(formulas), .combine='list') %dopar% {\n  lm(frm, data = diamonds)\n}\nend <- proc.time()\nprint(end - start)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   user  system elapsed \n   0.10    0.01    0.37 \n```\n\n\n:::\n\n```{.r .cell-code}\ndoParallel::stopImplicitCluster()\n```\n:::\n\n\n<br>\n\n## Session Info\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsessionInfo()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nR version 4.3.2 (2023-10-31 ucrt)\nPlatform: x86_64-w64-mingw32/x64 (64-bit)\nRunning under: Windows 10 x64 (build 19045)\n\nMatrix products: default\n\n\nlocale:\n[1] LC_COLLATE=English_Australia.utf8  LC_CTYPE=English_Australia.utf8   \n[3] LC_MONETARY=English_Australia.utf8 LC_NUMERIC=C                      \n[5] LC_TIME=English_Australia.utf8    \n\ntime zone: Australia/Perth\ntzcode source: internal\n\nattached base packages:\n[1] parallel  stats     graphics  grDevices utils     datasets  methods  \n[8] base     \n\nother attached packages:\n [1] doParallel_1.0.17 iterators_1.0.14  foreach_1.5.2     lubridate_1.9.3  \n [5] forcats_1.0.0     stringr_1.5.1     dplyr_1.1.4       purrr_1.0.2      \n [9] readr_2.1.5       tidyr_1.3.1       tibble_3.2.1      ggplot2_3.5.1    \n[13] tidyverse_2.0.0  \n\nloaded via a namespace (and not attached):\n [1] gtable_0.3.5      jsonlite_1.8.8    compiler_4.3.2    tidyselect_1.2.1 \n [5] scales_1.3.0      yaml_2.3.8        fastmap_1.1.1     R6_2.5.1         \n [9] generics_0.1.3    knitr_1.46        htmlwidgets_1.6.4 munsell_0.5.1    \n[13] pillar_1.9.0      tzdb_0.4.0        rlang_1.1.3       utf8_1.2.4       \n[17] stringi_1.8.3     xfun_0.43         timechange_0.3.0  cli_3.6.2        \n[21] withr_3.0.0       magrittr_2.0.3    digest_0.6.35     grid_4.3.2       \n[25] rstudioapi_0.16.0 hms_1.1.3         lifecycle_1.0.4   vctrs_0.6.5      \n[29] evaluate_0.23     glue_1.7.0        codetools_0.2-20  fansi_1.0.6      \n[33] colorspace_2.1-0  rmarkdown_2.26    tools_4.3.2       pkgconfig_2.0.3  \n[37] htmltools_0.5.8.1\n```\n\n\n:::\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}