{
  "hash": "3cbb6402fa576c4bdfb401643d78e941",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"AI in Biostatistics\"\noutput: html_document\ndate: \"2024-05-06\"\nauthor: \"Dr Matthew Cooper, Wesley Billingham\"\ncategories:\n  - AI\n  - R\ndraft: true\n---\n\n\n# Overview\n\nAI is a hot topic in most fields right now, and biostatistics is no exception! We (the Telethon Kids Institute biostats team) were asked to present at the weekly Institute seminar on the use of AI in statistical workflows.\n\nThe term AI has many meanings depending on the context - in this article we are referring exclusively to (and use the term interchangeably with) large language models (LLMs) such as ChatGPT and Claude. These tools are useful not just for writing sentences and paragraphs of text, but also functioning code!\n\nSince first investigating the capabilities of ChatGPT at writing R code, our team has been working to utilise it safely and effectively in our everyday workflows.\n\nThe summary of our message to the Institute staff was that we cannot ignore the massive increase in efficiency that AI ***can*** bring if used properly. However, we also need to stress its limitations and the need for human experts to validate any non-trivial output.\n\nThis is part one in a two part series. This part will look at the capabilities of AI to benefit our workflows and increase efficiency. The next part will look at some limitations of the technology as it currently exists, including some practical recommendations to identify these issues.\n\n## Format of this post\n\nWe will work through a couple of practical examples of how we might use AI in an everyday workflow:\n\n1.  **Data Visualisation**\n\n2.  **Statistical Analysis**\n\n3.  **Bonus - Shiny App Development**\n\nIn these examples, we will increasingly take out hands off the wheel and allow AI (in these examples, ChatGPT 4.0) to perform more and more of the task.\n\n# Example 1 - Data Visualisation\n\nA couple of summers ago (2021/22) felt unusually hot in Perth, Australia. Specifically, it seemed that the maximum temperature was always somewhere in the realm of 35 to 40 degrees Celsius. My colleague, being a statistician, wished to compare this summer to previous summers to determine if this suspicion was justified.\n\nHe whipped up a quick plot using ggplot2, attempting to show the number of days above a certain maximum, shown below updated up to January 2024:\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](weather_p1.jpeg){fig-align='center' width=700px}\n:::\n:::\n\n\nHere we can see the number of days over a certain maximum for each year since 2010. For example, in 2023, Perth had 0 days above 40째C and 4 above 38째C.\n\nThe sweltering summer in question had a whopping 12 days over 40째C and 23 above 38째C. Since the next highest count since 2010 was 7 and 14 respectively, its fair to say this was quite the outlier!\n\nMy colleague felt that the data visualisation could probably be cleaner and more clear, so enlisted ChatGPT for help (for one of the first times!).\n\n## Providing the Blueprint\n\nChatGPT allows the user to provide images as a part of prompts. With that in mind, the image was uploaded first by itself. ChatGPT was able to successfully identify the key elements of the plot just from the image (!), and so the next step was to give some guidance to make the plot more visually appealing.\n\nWith just one prompt: \"can you facet wrap the min max data\", in addition to the original plot, it got to work. Once the original data was provided, it was able code a new plot using Python (R cannot be run within ChatGPT, though we certainly could have requested R code to run ourselves instead).\n\nHere is the entire prompt history, from beginning to end. One image, one command and some data was all the context required to understand approximately the desired output. We say approximately, since some key information such as the counts above certain levels, is absent from this first attempt.\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](weather_p3.png){fig-align='center' width=700px}\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](weather_p4.png){fig-align='center' width=700px}\n:::\n:::\n\n\n## End Result and Discussion\n\nAfter some further refinement and back-and-forth, we arrive at a much-improved plot which more closely captures the spirit of the original, while improving the colour scheme and facetting the data.\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](weather_p8.png){fig-align='center' width=700px}\n:::\n:::\n\n\nPlots are a great use-case of AI, since the nitty gritty of colours, panes, text, etc can be a time-consuming hassle to do manually. AI in our experience does a good job of translating our descriptive visual prompts into code that achieves the described vision. Furthermore, the output is instantly verifiable (keep this point in mind!) and easy to refine.\n\n# Example 2 - Statistical Workflow\n\nThe following example was created specifically for our presentation. We wanted to mimic a researcher with a passing understanding in statistics, but no expertise, as they attempt to run through an entire statistical pipeline from design to analysis. This would involve more careful and lengthy prompting than the previous example.\n\nFor the example, we downloaded a data set contacting simulated lung data for 8528 individuals. It can be found here:\n\nhttps://stats.idre.ucla.edu/stat/data/hdp.csv (NOTE clicking the link initiates a download of the data.)\n\nThe data has the following variables of interest for our example:\n\n-   **Outcome**\n    -   remission (0/1)\n-   **Patient-level variables**\n    -   IL6 levels\n    -   CRP levels\n    -   Length of hospital stay\n    -   Family history\n    -   Cancer stage\n-   **Physician-level variables**\n    -   Physician experience\n    -   Physician ID\n    -   Hospital ID\n\nWe will be very careful to avoid statistical terminology as we prompt ChatGPT, but we can see that there is an implied nesting structure to our data, with patient inside physician inside hospital. With that in mind, and the fact that our outcome is binary, we are hoping that ChatGPT suggests a hierarchical logistic regression.\n\n## Providing the Problem\n\nIn this example, we provided ChatGPT with a very high-level summary of our data and research question, as seen here:\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](log_reg_1_v2.png){fig-align='center' width=700px}\n:::\n:::\n\n\nAgain, we have tried to use prompts that anyone with some familiarity with stats and data analysis would be able to replicate and understand. Here, we simply mention to ChatGPT that there are patients, doctors and hospitals (highlighted above).\n\n## The Response\n\nAmazingly, especially if you have had limited exposure to AI, these high-level, lay descriptions of our data and research questions were sufficient for ChatGPT to suggest a mixed-effects logistic regression model. It recognised the binary outcome and the hierarchical structure of the data, and proceeded to provide R code to perform the analysis.\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](log_res_2_v2.png){fig-align='center' width=700px}\n:::\n:::\n\n\nHere is where we encounter a difference from our previous visualisation example, however. For someone unfamiliar with statistics, would they have known if this answer happened to be incorrect? (keep that in mind! #2).\n\nFor now, we do recognise that it has selected an appropriate model to get started. An impressive feat!\n\n## End Result and Discussion\n\nFor brevity's sake, we will not include the whole prompting process here. However, following the model specification, ChatGPT was able to successfully guide us through adding a random slope, and then summarising our model using the *broom.mixed* package (broom for mixed models, as the name suggests).\n\nIt then gave us code to check the model fit, run model diagnostics, and perform sensitivity analysis. At each stage, it was able to give advice on interpretation and next steps that we could not fault. Here are some highlights:\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](log_reg_6.png){fig-align='center' width=700px}\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](log_reg_4.png){fig-align='center' width=700px}\n:::\n:::\n\n\n# Bonus Example - Shiny App\n\nWe now move to a more advanced programming exercise, and simultaneously lean more heavily on ChatGPT to do the bulk of the work for us. In this example, we wanted to create a [Shiny App](https://shiny.posit.co/). We want this app to import a dataset containing columns of personally identifiable information (PID) and exports a new dataset which masks this PID, maintaining the structure/distribution of the original data.\n\n## Providing the Idea\n\nSimilar to example 2, we're interested in how ChatGPT performs with minimal prompting and technical jargon. Our inital request looks like this:\n\n## Refinement\n\n## End Result and Discussion\n\nIn this first part, we have seen how easy and powerful the use of AI can be in the data analysis and statistical workflow. In part two, we will look at some pitfalls of AI and some traps we can fall into. We'll see if we can determine some good rules-of-thumb for its use to ensure our AI-assisted work remains both efficient and accurate.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}