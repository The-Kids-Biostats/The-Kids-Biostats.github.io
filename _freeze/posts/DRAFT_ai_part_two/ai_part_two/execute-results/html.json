{
  "hash": "62171322d019acfb5fdbc1a01a4913fe",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"AI in Biostatistics - Part 2\"\noutput: html_document\ndate: \"2024-05-06\"\nauthor: \"Dr Matthew Cooper, Wesley Billingham\"\ncategories:\n  - AI\n  - R\ndraft: true\n---\n\n::: {.cell}\n\n:::\n\n\n\n# Overview\n\nIf you haven't read part one of this two-part series on AI, do that first here:\n\nLast time we looked at three cases where our use of AI aided our productivity and gave us the desired result. In this post, we'll be looking at the other side of the coin to situations where AI has struggled and attempts to use it in these situations would hinder our productivity and potentially give us incorrect output.\n\nTo demonstrate this point, we'll look through the results of a few published papers and some concepts they introduce. Then we will examine some guidelines we can use to maximise our efficiency by using AI appropriately.\n\n# Examples\n\n## Example 1 - Jagged Frontier\n\nOur first example is drawn from a 2023 paper which looked at the effect of AI use on productivity and quality of work. You can read the paper here:\n\n<https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4573321>\n\nIt introduces a very helpful concept - the 'Jagged Frontier'. Below we use ggplot2 to demonstrate this idea.\n\n### What is the Jagged Frontier?\n\nImagine you have 5 tasks to complete today, and you are trying to decide which of these you can delegate to AI (in this case, ChatGPT). You might have in mind that each task has some implicit difficulty associated with it, and your perception of current AI technology is that in is capable of tackling tasks with a difficulty of up to 5. This is represented by the blue dashed line. \n\nYour 5 tasks have various difficulties, represented by the black points. At this point, based on your perception of the difficulty of your tasks and the capability of AI, you would assign tasks 2, 3 and 5 to ChatGPT, since these have a difficulty of <=5. \n\nUnfortunately, the reality is that our perception of difficulty does not line up well with AI's capabilities. As we have seen in the last post, it can complete some pretty incredible tasks, such as coding Shiny apps and performing advanced statistical analyses. But as we will also see later, it can struggle with some pretty mundane tasks. \n\nAnd so the capability of AI cannot be measured by the blue dashed line, but rather the red, *jagged* line, a seemingly random level of capability which is unrelated to our ideas of difficulty. This is what is referred to as the \"Jagged Frontier\". \n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](ai_part_two_files/figure-html/unnamed-chunk-2-1.png){width=1152}\n:::\n:::\n\n\n### Why should we care?\n\nWhen a task is achievable using AI, we refer to that task as being 'Inside the Frontier'; that is, below the red jagged line above. If AI would struggle or be unable to do a task, that would then be 'Outside the Frontier'.\n\nThe study above set out to investigate the difference in worker productivity when AI is used for tasks within its capability as opposed to not. A large study was set up, with the following methodology:\n\n1. All 758 participants (experts in the relevant field) complete a baseline project without any AI use. Speed and quality are measured. \n2. Participants are randomised into one of four groups (see table below). \n\n\n::: {.cell}\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table\" style=\"margin-left: auto; margin-right: auto;\">\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> Metric </th>\n   <th style=\"text-align:right;\"> Inside.Frontier </th>\n   <th style=\"text-align:right;\"> Outside.Frontier </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> ChatGPT </td>\n   <td style=\"text-align:right;\"> 189 </td>\n   <td style=\"text-align:right;\"> 190 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> ChatGPT + Overview </td>\n   <td style=\"text-align:right;\"> 190 </td>\n   <td style=\"text-align:right;\"> 189 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n\n3. Those in the \"Inside Frontier\" group were assigned a project that had been determined beforehand to be within the capabilities of ChatGPT 3.5. In contrast, the \"Outside Frontier\" group were assigned a project beyond the capabilities of ChatGPT 3.5.  \n4. The participants were further divided into \"ChatGPT\" and \"ChatGPT + Overview\" groups. The latter received some training on prompt engineering before undertaking the project.\n5. All participants completed their project, and their speed and quality was compared to their own individual baseline score.\n\nThe results are quite striking:\n\n\n::: {.cell}\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table\" style=\"margin-left: auto; margin-right: auto;\">\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> Metric </th>\n   <th style=\"text-align:left;\"> Inside.Frontier </th>\n  </tr>\n </thead>\n<tbody>\n  <tr grouplength=\"2\"><td colspan=\"2\" style=\"border-bottom: 1px solid;\"><strong>ChatGPT</strong></td></tr>\n<tr>\n   <td style=\"text-align:left;padding-left: 2em;\" indentlevel=\"1\"> Speed </td>\n   <td style=\"text-align:left;\"> 28% </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;padding-left: 2em;\" indentlevel=\"1\"> Quality </td>\n   <td style=\"text-align:left;\"> 38% </td>\n  </tr>\n  <tr grouplength=\"2\"><td colspan=\"2\" style=\"border-bottom: 1px solid;\"><strong>ChatGPT + Overview</strong></td></tr>\n<tr>\n   <td style=\"text-align:left;padding-left: 2em;\" indentlevel=\"1\"> Speed </td>\n   <td style=\"text-align:left;\"> 23% </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;padding-left: 2em;\" indentlevel=\"1\"> Quality </td>\n   <td style=\"text-align:left;\"> 43% </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\nUsing ChatGPT for the project within the frontier resulted in considerable improvements in both speed and quality of work, regardless of whether participants received training. \n\nBut perhaps more interestingly, the groups with projects outside the frontier saw a decrease in quality of work, even though the work was faster. \n\nWe will return to these results in the discussion below. \n\n\n## Example 2 - Biostatistical Questions\n\nAs promised, we are going to investigate some examples of tasks that lie 'Outside the Frontier'. These examples are drawn from this paper:\n\nhttps://www.ncbi.nlm.nih.gov/pmc/articles/PMC10646144/\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](ai_part_two_files/figure-html/unnamed-chunk-5-1.png){width=1152}\n:::\n:::\n\n\n# Discussion\n\nWhen we presented this material to researchers at the Institute, our objective was to steer listeners away from the two extreme attitudes they might take towards AI use in their work. \n\nThe first extreme is to not use AI whatsoever. As we have clearly seen from part one of this blog series, and the results of the 'jagged frontier' study, the increases in productivity can be astonishing. If any tool increases our work speed by 30-40% while maintaining or even improving quality, it ought to be used. \n\nThe second extreme is the overuse and/or over-reliance on AI. Some tasks are simply outside the current capabilities of AI (not to say they will remain so in the future). To use AI in such circumstances wastes time at best, and at worst produces inaccuracies that remain unnoticed by us even up to publication of our work. The worked biostatistics example above shows how easy it is to be convinced by the confident language of AI as it repeats an answer that is patently incorrect. \n\n## Where to from here?/Our Recommendations\n\nThe 'jagged frontier' of AI is invisible to us, and hence we often cannot know whether the task we are about to delegate is within its capability. For this reason, we propose the following guidelines to ensure you are using AI effectively and responsibly:\n\n1. You should be able to verify the output is true/accurate. \n2. The time it would take to verify the AI output should be less than the time it would take to achieve the same output yourself. \n\nLooking back at our examples throughout the two posts:\n\n### Weather plot\n\nIn this example, we could verify the more complex plot by visually comparing it to simple plots we coded ourselves. Additionally, we could understand the R code that AI produced. Whether the use of AI in this case was justified or not depends on how quickly we could have remembered all the ggplot2 commands and done it ourselves. \n\n### Statistical Analysis\n\nFor the statistical analysis, we were well placed to verify the suggestions of ChatGPT. However, this would be a dangerous use-case for someone who is unfamiliar with statistical methods. We know that the suggested hierarchical mixed models is a good suggestion, but this would not be immediately verifiable to everyone. Therefore we would recommend against this use-case for non-statisticians. \n\n### Shiny App\n\nThis is probably the best example of AI saving time and increasing quality. The objective is simple - a Shiny App which takes and randomises data. Even as someone who has never coded a Shiny App before, it is easy to verify whether it works by simply using the app. \n\n### Mathematical Questions\n\nFinally, we have seen that AI can make mistakes when calculating numerical results, and remain confidently incorrect in the face of correction. To verify the answer requires working line by line through each piece of code to ensure it is doing what we asked. Hence it is unlikely to save us time and seemingly likely to be incorrect. \n\n# Conclusion\n\nThese two posts have been a summation of our thoughts as they have developed through the first year of incorporating AI into our workflows. We have sought to experiment with different prompts to see where we can use AI to improve our productivity and where it hampers it. The two guidelines above have been helpful to avoid over-reliance, and our experiences with effective AI have helped to avoid under-utilisation. \n\nWe'd love to hear your thoughts and ideas on these two posts. Do you disagree with our recommendations and/or conclusions? Or perhaps you have some additional ones you would like to suggest. \n\n## Further reading\n",
    "supporting": [
      "ai_part_two_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../../site_libs/kePrint-0.0.1/kePrint.js\"></script>\n<link href=\"../../site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}